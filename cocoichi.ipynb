{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zukako/.pyenv/versions/anaconda3-4.0.0/envs/keras/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPool2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# データの前処理のため\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, list_pictures, load_img\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "co_list=os.listdir('./co/')\n",
    "cu_list=os.listdir('./cu/')\n",
    "\n",
    "# 対象Aの画像\n",
    "for picture in co_list:\n",
    "    img = img_to_array(load_img('./co/{}'.format(picture), target_size=(75,75)))\n",
    "    X.append(img)\n",
    "    Y.append(0)\n",
    "\n",
    "\n",
    "# 対象Bの画像\n",
    "for picture in cu_list:\n",
    "    img = img_to_array(load_img('./cu/{}'.format(picture), target_size=(75,75)))\n",
    "    X.append(img)\n",
    "    Y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 画素値を0から1の範囲に変換\n",
    "X = np.array(X).astype('float32')\n",
    "X = X / 255.0\n",
    "\n",
    "# クラスの形式を変換\n",
    "Y = np_utils.to_categorical(Y, 2)\n",
    "\n",
    "# 学習用データとテストデータ\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(75,3,input_shape=(75,75,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(75,3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(1.0))\n",
    "\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "adam = Adam(lr=1e-4)\n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 274 samples, validate on 135 samples\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 32s 116ms/step - loss: 0.3665 - acc: 0.8504 - val_loss: 0.5947 - val_acc: 0.7037\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 35s 130ms/step - loss: 0.2713 - acc: 0.8759 - val_loss: 0.5597 - val_acc: 0.7259\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 35s 128ms/step - loss: 0.2028 - acc: 0.9416 - val_loss: 0.6879 - val_acc: 0.7259\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 36s 131ms/step - loss: 0.1085 - acc: 0.9854 - val_loss: 0.7215 - val_acc: 0.7259\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 35s 128ms/step - loss: 0.0764 - acc: 0.9745 - val_loss: 0.8205 - val_acc: 0.7111\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 34s 123ms/step - loss: 0.0538 - acc: 0.9927 - val_loss: 0.8581 - val_acc: 0.7037\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 35s 126ms/step - loss: 0.0336 - acc: 1.0000 - val_loss: 1.2398 - val_acc: 0.7185\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 37s 136ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 1.0498 - val_acc: 0.7037\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 38s 139ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 1.1316 - val_acc: 0.7037\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 39s 143ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 1.2337 - val_acc: 0.7407\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=5, epochs=10,\n",
    "                   validation_data = (X_test, y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('param.hdf5')\n",
    "json_string = model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = img_to_array(load_img('./cu/1-005.jpg', target_size=(75,75)))\n",
    "a = np.array([img])\n",
    "model.predict_classes(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras36",
   "language": "python",
   "name": "keras36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
